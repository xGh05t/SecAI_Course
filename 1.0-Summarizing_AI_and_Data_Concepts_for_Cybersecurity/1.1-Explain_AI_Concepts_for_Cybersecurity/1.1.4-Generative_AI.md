
# 1.1.4 Generative AI (Video Transcript)

## 1. Introduction to System Performance and Open Web UI
OK so I've got a couple things on the screen
here.
1 is to show my system performance here on the
right hand side and on the left hand side I
have a tool called Open Web UI and this allows
me to access various different types of large language models
all from the same interface.

## 2. Local vs Cloud Models
This little drop down selection here.
I've got a few models available.
This mistral one and this phi3 one are actually running
on my computer.
Those models have been downloaded and run here and will
leverage the graphics card on my computer when I ask
it questions.
And then the other ones all exist in open AI's
cloud and their massive data centers.
Why I would pick a local one versus a cloud
one?
Well, the local one gives me full control and if
I have privacy concerns, for example, I know that all
my data is staying and is being processed in my
own environment.
Let's take a quick look.

## 3. Processing Questions with Local Models
So what'll happen here?
If I pick a local model like Mistral, for example,
when I ask it a question, that question is going
to be processed by the model that's running on my
computer.
So over here on the right hand side, you'll see
my graphics processor.
You should see up here.
It's starting to work hard and you'll see the utilization
peak a little bit as it processes the question and
generates the output.
I've got a prompt that I'll use here to ask
you to create a Python script, and I'll paste that
in and we'll say go.
You see the spike there?
That question is being processed by my graphics card.
My processors didn't really handle it right.
Graphics cards are what's needed to really run AI well.
If I were to ask a similar sort of question,
create a Python script to print Hello, world to the
screen, and I'll pick a different model, cloud model here.

## 4. Using AI for Script Generation
We'll go with GPT 4.
I don't see that big spike.
You know, the graphics card, like I did before that
question was processed by open AI's systems on the Internet
as opposed to locally.
Without the graph here to sort of see, you know,
where that question is being processed, it's hard to really
understand what's happening because of the answers are all within
this one UI.
And what's great about this tool is that allows me
to run both local and remote models all from the
same place.
OK, now the other thing I could do, let's start
a new chat.
Let's say I just asked a really generic question.
AI is always going to provide an answer regardless of
what I put in it.
If I said, for example, create a bash script to
check SSL certificates, I haven't really told it what I'm
trying to accomplish, why I want to check them, what
information it is I'm trying to determine, but it's still
going to answer.

## 5. Understanding AI Responses
It's still going to give me a script and it's
going to have to make some assumptions about what it
is that I need.
If I were to be much more specific, for example,
if I told it exactly what I wanted like this,
write a bash script that performs the following actions.
Read a list of domains from a file called domains.txt.
For each domain, check the certificate expiration date.
Calculate how many days are left until it expires.
If it's expiring within 30 days, print a warning and
put comments in the code to help me understand how
it works and what it does.
And it's going to say, OK, and it gives me
exactly that.
The prompt that I provide and how thoughtful I am
in the way that I asked the question is going
to have a direct impact on what those outputs look
like.

## 6. Providing Context for AI Queries
If I don't ask it for enough details, it's going
to make some assumptions.
Now, another thing is I would like to use the
AI to help me maybe interpret or understand something.
Now, if I were just to ask AI to tell
me about vulnerabilities in my environment, how on earth would
it know how to answer that question?
It's going to try.
If I said tell me about vulnerabilities in my environment,
I haven't provided any context here at all about what
that means.
Am I talking about cybersecurity vulnerabilities, people vulnerabilities, physical vulnerabilities?
It's going to try to answer.
It's kind of telling me if that's really open-ended question,
I need to be more specific, actually give it some
info.
So what I've got here on my computer, a bunch
of vulnerability scan files that will run on a lab
environment here.
I can upload those results files.
It's going to process them the reading and interpreting what's
there and then I can say summarize the vulnerabilities described
in these documents and we'll see what it gives us.

## 7. Validating AI Outputs
I just got to think through and read what's there
and it's telling me about what that is, right?
It tells me about specific CVE's in my environment and
the utilities that were run IP addresses perhaps.
I could even ask it list the top three vulnerabilities.
Let's see if it's able to answer that.
It's a little bit of a vague question, but again,
it's going to pull the information out of the docs
that I provided, and it's telling me about the CVE's
that were identified in the environment in which I performed
the scan.
Without providing it with the docs.
It could never answer this.
Now the other thing I have to be careful of
though.
I've always got to validate these outputs because AI can
sometimes hallucinate and start another new chat.

## 8. Testing AI with Recent Data
So, for example, an AI model is going to be
trained on a data set.
There's going to be a point in time where the
data ends, right?
They're going to collect the data and then they're going
to use it to train the model.
So there's going to be a cut off period.
It's going to be really recent things that I know
the model shouldn't be able to tell me about.
And a great example of that would be to get
a specific vulnerability.
So I'm going to switch to my local model here.
I'm going to pull up here the CISA Known Exploited
Vulnerabilities website, and this lists known vulnerabilities that CISA has
identified threat active groups are actively exploiting to try to
gain unauthorized access to government websites and things.
And there's several of them here.
And so let's just pick this first one.
It doesn't really matter.
This one is fairly recent.
2025 gives you a clue.
That was this year.
It's definitely outside of the training set for Mistral, but
I'm going to ask anyway.
Summarize and I'll put it in.
Let's just make sure that it's only the text and
Mistral is going to think about that for a little
while.
Now.
Remember, this is running on my computer here and it
comes back and it tells me that it's a hypothetical
vulnerability that's not been officially documented or assigned yet.
Is that true?
No, not at all, right?
We literally pulled it from a site that's telling me
that threat active groups are packing that right now.
It's hallucinating.
It's telling me a bunch of gobbledygook, right, about what
that is.
That's completely wrong.
It's very convincing, but totally wrong.
What I would like to see, perhaps we'll see this
with one of the cloud models.
When I ask it that same question, it should hopefully
tell me that's outside of my training set or I
won't provide specific information about CVE's or something like that.
The little bit better job avoiding those hallucinations.
So I've always got to test my outputs.
Even with the scripts that we saw earlier, they look
quite convincing, but you've got to test and validate these
things in order to verify that they really are what
they appear to be.