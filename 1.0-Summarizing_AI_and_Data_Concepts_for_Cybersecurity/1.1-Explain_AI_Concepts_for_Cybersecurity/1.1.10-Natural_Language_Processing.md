
# 1.1.10 Natural Language Processing

Natural language processing (NLP) enables computers to understand, interpret, and generate human language. It is a branch of artificial intelligence focused on teaching machines to process and analyze large amounts of natural language data, making it possible for computers to read, understand, and interact using human language.

In cybersecurity, NLP is especially important because it helps security teams process vast volumes of unstructured text data from sources like logs, threat reports, chat messages, and emails. Key NLP applications in cybersecurity include analyzing and categorizing threat intelligence, extracting indicators of compromise from reports, understanding intent in user communications (such as phishing detection), and automating responses. Common SOC patterns include: retrieval-augmented generation (RAG) over tickets/alerts/runbooks, schema-validated JSON outputs for tool actions, and function-calling into SIEM/SOAR/TIP for safe automation.

For example, NLP can be used to cluster and classify security alerts, identify emerging threats from dark web monitoring, or extract malicious IP addresses and URLs from textual threat intelligence feeds. This ability to process language data at scale allows security analysts to focus on high-value tasks while improving detection and response efficiency. Because models can hallucinate or be prompt-injected, organizations typically pair NLP with guardrails (input/output filtering, allow-listed tools, and audit logging) and keep high-risk actions behind human approval.

## Large and Small Language Models

**Large language models (LLMs)**, like OpenAI's GPT models, are highly capable and used extensively in complex tasks such as summarizing threat intelligence reports, generating security playbooks, and interacting with users via conversational security bots. LLMs are useful for generating large volumes of text, and can be misused by threat actors to craft convincing phishing emails or social engineering scripts. Large language models (LLMs) are characterized primarily by very high parameter counts, typically measured in the tens to hundreds of billions of parameters. Due to their size, LLMs require substantial memory and compute power. Generally, LLMs require one or more high-memory GPUs (graphics processing units) or specialized components such as inference accelerators with 40–80 GB or more of RAM. Training LLMs from scratch requires dozens or even thousands of GPUs or accelerator devices, fast CPUs, vast amounts of system memory, very fast networked storage, and very high-bandwidth interconnects to support distributed training.

**Small language models (SLMs)** are lighter and faster, making them ideal for real-time monitoring tasks on limited resources, such as analyzing logs, identifying suspicious behavior, or quickly classifying security alerts. While they lack the extensive knowledge and capabilities of LLMs, SLMs are more efficient and can be integrated into security appliances or embedded systems where resources are limited. SLMs have much lower parameter counts than LLMs, ranging from a few million to the low-billion range. Architecturally, they are often optimized for efficiency, and their hardware requirements are modest compared to LLMs. Many SLMs run sufficiently well on "everyday" CPUs with modest amounts of RAM. A single dedicated GPU can significantly improve performance; in particular, NVIDIA's RTX series is well supported and greatly enhances SLM performance. The small-model design emphasizes low latency, lower operational cost, and suitability for running locally or on-premises, while falling short of the features and capabilities of large models. SLMs (1–8B parameters) are frequently adapter-tuned for domain terms and excel at low-latency classification or summarization, while larger LLMs remain better for open-ended reasoning

## Using Python to Perform Sentiment Analysis

Using Python, try running this code in a Jupyter Notebook and review the results of the sentiment analysis performed on the sample log data it includes.

```
# Import libraries
from transformers import pipeline  # For sentiment analysis
import matplotlib.pyplot as plt  # For making a bar chart
import sys  # To handle errors

# Step 1: Set up the sentiment classifier
# This loads a pre-trained model that decides if text is positive (good) or negative (bad)
try:
    classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")
    sys.exit(1)  # Stop the program if the model fails to load

# Step 2: Create a list of network security log messages
# These are like alerts from a system monitoring network traffic (like CIC-IDS-2017)
logs = [
    "Suspicious file detected during scan.",  # Sounds like a problem
    "Network traffic normal, no issues found.",  # Sounds good
    "Multiple failed login attempts detected.",  # Sounds bad
    "System update completed successfully.",  # Sounds good
    "High packet rate: possible DDoS attack."  # Sounds bad
]

# Step 3: Analyze each log message
# Store results to show later
results = []
for log in logs:
    if log.strip():  # Check if the log is not empty
        result = classifier(log)[0]  # Get the sentiment (positive or negative)
        results.append({
            'log': log,
            'label': result['label'],  # POSITIVE or NEGATIVE
            'score': result['score']   # Confidence score (0 to 1)
        })
    else:
        print("Skipping empty log message.")

# Step 4: Print results in a clear way
print("\nResults of Sentiment Analysis:")
print("-----------------------------")
for res in results:
    print(f"Log: {res['log']}")
    print(f"Sentiment: {res['label']} (Confidence: {res['score']:.2f})")
    print("-----------------------------")

# Step 5: Create a bar chart to show how many logs are positive vs. negative
# Count positive and negative labels
positive_count = sum(1 for res in results if res['label'] == 'POSITIVE')
negative_count = sum(1 for res in results if res['label'] == 'NEGATIVE')

# Make the bar chart
labels = ['Positive (Benign)', 'Negative (Attack)']
counts = [positive_count, negative_count]
colors = ['green', 'red']  # Green for positive, red for negative
plt.bar(labels, counts, color=colors)
plt.title('Sentiment Analysis of Network Logs')
plt.ylabel('Number of Logs')
plt.show()
```

## Generative Adversarial Networks

**Generative adversarial networks (GANs)** consist of two neural networks contesting each other, one generating synthetic data samples and another distinguishing real from fake. This competitive training process makes GANs especially powerful for generating realistic data. GANs are widely used in various fields, including image synthesis (creating new images that look like real photos), data augmentation (generating synthetic data to train AI models more effectively), and realistic scenario simulation (creating fake but believable scenarios to test systems and train models). This means, for example, that GANs could be used to generate realistic phishing emails or malware samples that help cybersecurity professionals train their detection systems and prepare for real-world attacks.

In cybersecurity, GANs play a vital role in generating synthetic but realistic threat scenarios for training and testing security systems. For example, they can create synthetic logs that resemble real-world attack patterns, enabling the development of robust intrusion detection systems. GANs can also be used to generate new malware variants for red team exercises or to test the resilience of machine learning-based security models against adversarial attacks.

Additionally, cybersecurity teams can share or analyze synthetic (fake) data for research or training without violating privacy rules. By using GANs to generate large, diverse, and realistic datasets, security professionals can train and validate AI models more effectively, leading to improved threat detection and response.

> [!NOTE]
> Diffusion models are now often preferred over GANs for general-purpose text-to-image and video generation. However, GANs remain important and highly useful for creating realistic human faces from scratch and on-device upscaling of low-resolution images and video.