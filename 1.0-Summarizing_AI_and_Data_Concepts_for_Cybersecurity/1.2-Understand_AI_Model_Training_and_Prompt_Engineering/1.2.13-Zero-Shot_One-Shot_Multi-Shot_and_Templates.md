
# 1.2.13 Zero-Shot, One-Shot, Multi-Shot, and Templates

This table outlines three AI prompting techniques (zero-shot, one-shot, and multi-shot) for analyzing cybersecurity artifacts like YARA rules, DNS queries, or Suricata alerts. It offers practical ideas for leveraging AI to facilitate rapid threat detection and response.

| Prompting Technique | Example | Operational Value | Risks |
| :---: | :---: | :---: | :---: |
| ***Zero-shot*** | Provide a raw YARA rule and ask, "Does this catch a new piece of ransomware, and why?" Or paste an unfamiliar DNS query and request a risk explanation. No prior examples are supplied. | Generates fast, creative insight when historical data is unavailable which is useful during first-hour incident response or threat-hunting. | Treat the answer as a hypothesis and validate against authoritative documentation or a sandbox detonation. |
| ***One-shot*** | Supply one labeled NetFlow record that is known benign, then present a second record and ask the model to classify it. | Transfers a simple pattern without large context windows (maximum amount of input a language model can manage at once), keeping token costs low. | Overfits (high performance on training data but poor performance on new, unseen data) to the single example, so if the lone record is atypical, the model generalizes poorly. Provide at least one representative artifact and review edge cases manually. |
| ***Multi-shot*** | Feed ten labeled Suricata alerts, five benign, five malicious, and request that the model label a new batch of alerts. | Approximates supervised learning, often reaching 80% or more precision in triage tasks while avoiding a full machine learning pipeline. Particularly effective for log types with recurring structures (e.g., Zeek HTTP logs). | Consumes more tokens and may unintentionally reveal proprietary indicators or customer IP ranges. Redact sensitive fields and monitor total prompt size to control cost. |

## Templates

Security programs succeed when every alert, artifact, and response step follows a predictable script. Prompt templates give language models the same operational discipline by ensuring their outputs follow a repeatable, standardized structure. This means the model's responses will consistently include the right fields, formats, and terminology required by security teams and automated tools, making integration into cybersecurity workflows easier for both beginners and experienced professionals. A template is simply a text file (often managed in Git alongside infrastructure‑as‑code) that contains placeholders such as {log_lines}, {vulnerability_id}, and {desired_format}. During runtime, an automation layer (for example, a small Python utility that reads from Kafka or S3) injects real telemetry into those placeholders and forwards the completed prompt to the LLM.

Imagine a daily cron job that gathers the ten largest security findings from the previous day's SIEM index. Here is a simple example of what a Jinja2 template (a type of text file that uses placeholders to insert data dynamically) might look like. This example helps generate a structured prompt that can be reused consistently:

```
You are a security knowledge base generator.

Data:
{{log_lines}}

Task:
Summarize each finding in two sentences, map it to the relevant CVE or CWE where possible, and output the final list as valid JSON.
```

The automation script collects the security logs from the previous day, replaces the {{log_lines}} placeholder with that log data, and saves the resulting prompt text file in the same shared folder or version-controlled storage location where security team procedures are kept. Each update is reviewed by colleagues to ensure accuracy. Sensitive information is scanned to prevent accidental inclusion. The file history enables the team to trace exactly which prompt text produced which AI-generated response, fostering accountability and transparency.

Templates pay dividends in two important ways that are highly relevant in cybersecurity operations. First, they guarantee consistency by ensuring that the model's outputs always use the expected field names, data formats, and structures. This prevents failures in dashboards, automated alerting systems, or log parsers that depend on predictable data. For example, a dashboard visualizing intrusion attempts will not break because a field suddenly changed from src_ip to source_ip. Second, templates support defense-in-depth by allowing every placeholder to be pre-sanitized, meaning sensitive information like user names, tokens, or email addresses can be removed, masked, or converted into hashes before leaving the secure environment. This layered approach reduces the risk of exposing confidential data when interacting with external AI services, helping teams meet privacy, compliance, and security requirements.