
# 1.2.10 System Roles and System Prompts

A straightforward, hands‑on exercise demonstrates how the ***system role*** steers the model's output. Begin by opening the free **OpenAI Playground** (https://platform.openai.com/playground) or the browser‑based HuggingFaceChatUI (https://huggingface.co/docs/chat-ui/en/index.) Copy the following real‑world artifact into the chat box:

192.0.2.44 - - [06/Jun/2025:12:45:11 -0500] "GET /wp login.php HTTP/1.1" 401 232 " " "Mozilla/5.0"

1. Leave the system field blank so the model inherits its default "assistant" persona, then press Submit. The response will likely describe the request in general terms (identifying the client IP, HTTP method, and response status) but provide little actionable context.
System Prompt with Explanation

| System Prompt with Explanation |
|:--:|
| ![](../pics/1.2.10.png) |
| *A screenshot of system prompts using Open WebUI.* |

> [!NOTE]
> The interface titled prompts is split into two panels. The left panel is for configuring the AI model, with a section for a system message to define the AI's behavior. The right panel shows a user's prompt, which is a line from an Apache access log, and the AI assistant's response. The assistant breaks down the log entry into its components, providing an explanation by field for elements like the IP address, timestamp, and HTTP request.

2. In the system field, paste the following directive: *You are a Security Operations Center (SOC) analyst. Analyze each Apache log line, assign a risk score from 0–10, explain why the score was chosen, and return a JSON block containing event_time, src_ip, http_path, http_status, and risk_score. If additional investigation is warranted, recommend the next step.*

Submit the same log entry again. This time, the model should highlight that the request targets the sensitive /wp‑login.php path, note the 401 "unauthorized" status as a potential brute‑force indicator, and wrap the analysis in clean JSON similar to:

```
{  
"event_time": "2025‑06‑06T17:45:11Z",  
"src_ip": "192.0.2.44",  
"http_path": "/wp‑login.php",  
"http_status": 401,  
"risk_score": 7,  
"recommendation": "Query firewall logs for repeated attempts from 192.0.2.44 and consider temporary
block if count > 5." 
}
```

| System Prompt with Recommendation |
|:--:|
| ![](../pics/1.2.10_2.png) |
| *A screenshot of a playground interface using Open WebUI.* |

> [!NOTE]
> The interface titled prompts is split into two panels. The left panel is for configuring the AI model, with a section for a system message to define the AI's behavior. The right panel shows the AI's response demonstrating it has followed the instructions. The response includes an assessment of a failed login attempt to a word press site, a risk score justification of 6 on 10, a formatted JSON output with the event details, and a recommendation to monitor for further suspicious activity from the source IP.

3. Replace the log entry with another data type, such as a clipped email header: *Received: from attacker.example.net (203.0.113.88) by mail.example.org; Fri, 6 Jun 2025 16:02:01 ‑0500*

*Subject: Urgent invoice attached*

or a Google CloudAudit event snippet:

```
{  
"protoPayload": {    
"methodName": "storage.objects.delete",    
"authorizationInfo":[{"permission": "storage.objects.delete","granted": true}],    
"request": {"bucket":"finance‑backups", "object": "q2‑2025‑ledger.csv"}  
},  
"resourceName":"projects/_/buckets/finance‑backups/objects/q2‑2025‑ledger.csv"
}
```

Re‑submit each artifact first with no system role and then with the SOC‑analyst role. Observe how the role‑guided responses consistently surface potential threats (e.g., suspicious sender domain, high‑risk cloud‑storage deletion) and structure the findings in machine‑readable JSON.

Running the experiment again with other everyday artifacts, such as a suspicious domain name from DNS logs, a firewall entry showing an unexpected outbound connection, or a Kubernetes audit record indicating a new cluster‑admin privilege grant, makes two real‑world benefits clear. A well‑defined system role deepens the analysis by nudging the model to apply context‑aware security reasoning. For example, it might automatically query an open threat‑intelligence feed to check whether the domain is associated with malware campaigns, flag the firewall log as potential data exfiltration because it uses an unusual destination port, or map the Kubernetes privilege change to a likely privilege‑escalation tactic. The consistent JSON layout eliminates the need for analysts to copy and paste or reformat results. SIEM and SOAR tools can ingest the model's output immediately, enrich it with geolocation data or asset criticality scores, and trigger automated containment steps. This end‑to‑end consistency shrinks the gap between detection and action from minutes to seconds, even when teams are sifting through hundreds of alerts per hour.