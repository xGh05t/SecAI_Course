
# 1.2.5 Federated Learning

While many AI training models involve a centralized location where data is stored and analyzed, federated, or collaborative, uses multiple clients to train the AI. The data used by the clients is kept on the client devices and not shared. This helps address privacy issues, unauthorized access to sensitive data, and regulatory compliance. Essentially, instead of the data being sent to the AI in a centralized location, the AI is sent to the data that is spread across multiple devices to train.

## Federated Learning Process

The first step in the **federated learning** process involves initializing a global machine learning model on a centralized server. From this server, the learning model is distributed or connected to selected client devices which can include computers, smartphones, and even IoT devices.

Next, the clients use their own data to train the learning model. How the client trains the model is configured by the server, but the important piece here is that the data stays on the local device.

Once the client device is done, it sends the model parameters and updates back to the central server. This includes updated weights and gradients, but again, none of the local data is sent back to the central server.

The central server then takes the updated model information from all the clients and typically aggregates them in some fashion. Oftentimes this is done by averaging the updates (a common method being federated averaging, or FedAvg) and applying this to the global model.

The last step is iterative training where the centralized server sends the model back to the same or a different set of clients and the learning process starts over again.

This process is repeated multiple times to refine the model until it achieves the desired level of accuracy or convergence.

## Challenges of Federated Learning

While federated learning has many advantages over other learning models, there are some unique challenges it presents.

One of the main challenges is device heterogeneity. The decentralized manner of federated learning can mitigate bias, but the challenge is that different devices may have more data than others and leads to a balancing issue. Devices with more data will skew the learning to those data-heavy devices which can lead to model drift.

Communication overhead is another concern with federated learning. While traffic is reduced compared to centralized data transfer, federated learning does still require a lot of communication between devices. If there is a large number of client devices or an unstable network, this can create issues with low bandwidth, latency, training time, and scalability.

Federated learning is susceptible to data poisoning attacks. If the attacker can inject malicious data during the training process on the client machines, this will affect the learning model. Attackers can also send bad gradients or weights to corrupt the model. Anomaly detection, adversarial training, strict access controls and other security measures can help safeguard against these attacks. All participating clients need to be authenticated and authorized to help prevent rogue devices pretending to be valid clients.

While federated learning does help to reduce direct data exposure, sensitive data can still be leaked while model updates are shared with the central server through gradients or model parameters through inference attacks. These attacks analyze and reconstruct data from model updates or compromised servers.

To mitigate this risk, secure aggregation should be used. Secure aggregation is when all user's data is encrypted and then sent to the server. The server decrypts the data only when enough updates are combined, revealing only the average of all updates. The server never sees a single user's data. Differential privacy is another technique that can be used to help protect the privacy of users. Different privacy adds carefully calibrated noise to all user's data so that each individual's contribution is hidden, but the overall results stay useful and accurate.