
# 2.1.2 AI Threat Modeling (Video Transcript)

## 1. Introduction to AI Risks
AI is transforming many different industries, but with innovation comes
new risks, and AI has vulnerabilities not seen in traditional
software.

## 2. Prompt Injection Attacks
For example, if maliciously crafted prompts are given to an
AI model, it can be tricked into making incorrect decisions.

## 3. Model Query Attacks
Or if attackers repeatedly query an AI model.
They can learn how the model works and reconstruct it.

## 4. Algorithm Theft
Essentially stealing proprietary algorithms without accessing the original code.

## 5. Data Leakage Risks
Attackers can steal other information by analysing outputs too, like
sensitive personal information used during model training.

## 6. Training Data Corruption
Speaking of training, if attackers inject corrupted or biased data
into training sets, the models behavior can be corrupted from
the start.

## 7. External Component Vulnerabilities
If your model uses external components like APIs that aren't
properly verified, that can corrupt your model and cause supply
chain vulnerabilities.

## 8. Inherent AI Vulnerabilities
APIs can also be abused by attackers to gain access
to model data if proper controls are not in place.
Even without interference from bad actors, AI systems have inherent
vulnerabilities too.

## 9. AI Threat Modelling Introduction
They can unintentionally memorize user data and then leak it.
Especially.
In generative models.
Like LLMs?
Or they can straight up hallucinate or have biases giving
misleading outputs that could pose reputational or legal risks.
So how do we defend against these risks and use
AI safely?
That's where AI threat modelling comes in.

## 10. Understanding the System
That's the structured process of identifying, assessing, and mitigating potential
threats in the AI and ML systems before they can
be exploited.
Several AI threat modeling frameworks support this process like these.
They offer standardized guidance for managing threats across the AI
life cycle.
It all starts with understanding the system.
What data does it collect?
Where is that data stored and where does it travel
to?
Gather key architectural documentation like data flow diagrams, network layouts,
and security architectures.

## 11. Mitigating Risks
They will help you understand data movement and map out
communication protocols, security boundaries, and 3rd party services being used.
This knowledge is essential for identifying potential attack surfaces and
assessing risks.
After that, how do you actually mitigate those risks?
That requires well defined security controls, network segmentation, secure APIs,
secret management, role based access and compliance with regional data
protection laws.

## 12. Continuous Effort in AI Threat Modelling
And those controls must align with how AI components interact
and evolve over time.
AI threat modelling is a continuous evolving effort.
It takes IT professionals like you to understand how systems
are designed so that organizations can implement the right safety
measures and better protect their AI from growing threats.